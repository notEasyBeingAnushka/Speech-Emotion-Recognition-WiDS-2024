## Why do we do Audio preprocessing?
Audio preprocessing is essential for improving the quality and consistency of audio data, which in turn enhances the performance of machine learning models. Key steps include noise reduction to remove unwanted sounds, normalization to standardize audio levels, and segmentation to break audio into manageable chunks. Feature extraction, such as obtaining Mel-frequency cepstral coefficients (MFCCs), transforms raw audio into meaningful representations. These preprocessing steps help reduce overfitting, improve computational efficiency, and ensure that models focus on relevant audio features. This leads to better accuracy and reliability in tasks like speech recognition, music classification, and other audio-related applications.

## Some important terms you need to know
- **Sampling Rate**: The number of audio samples per second. A higher sampling rate captures more detail in the audio signal.
- **Amplitude**: The loudness or volume of the audio signal. Higher amplitude corresponds to louder sound.
- **Frequency**: The number of wave cycles per second, determining the pitch of the sound.
- **Waveform**: A graphical representation of how the amplitude of the audio signal varies over time.
- **Spectrogram**: A visual representation of the frequency content of an audio signal over time, used for detailed analysis of its spectral properties.
- **Pitch**: The perceived frequency of a sound, often associated with musical notes or speech tone.
